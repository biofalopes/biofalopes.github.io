<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on Fabio M. Lopes</title>
    <link>https://www.fabiolopes.tk/tags/python/</link>
    <description>Recent content in python on Fabio M. Lopes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 20 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.fabiolopes.tk/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using Python and Docker to monitor Ceph S3 from outside</title>
      <link>https://www.fabiolopes.tk/blog/python-s3-monitoring/</link>
      <pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.fabiolopes.tk/blog/python-s3-monitoring/</guid>
      <description>I needed to perform external monitoring on our S3 endpoints to better observe how the service was performing, thus getting a better representation of user experience. I use basically Python and Docker to accomplish the task.
 We have two relatively large Ceph clusters (2.5PB, 600 OSDs) at the company that provides object storage using implementing the S3 API, so we can leverage the AWS SDK and use it to perform operations like creating buckets, putting objects and so on, and measuring the success and the time consumed to perform each operation.</description>
    </item>
    
    <item>
      <title>Web scrapper using Python</title>
      <link>https://www.fabiolopes.tk/blog/python-web-scrapper-fii/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.fabiolopes.tk/blog/python-web-scrapper-fii/</guid>
      <description>So I needed to learn how to scrape a web page using Python.
 My teammate suggested that I could learn a few tricks in python by scraping FIIs, which is the brazilian equivalent to american REITs. I did some research and found some good examples using a module called pandas (https://realpython.com/python-csv/) , a tool designed for data analisys and manipulation and very popular among people working with data science. My goal was much less ambitious but i thought i might as well use what everyone else is using, since it would provide a good learning opportunity.</description>
    </item>
    
    <item>
      <title>Comparsion of Sorting Algorithms using Python Decorators</title>
      <link>https://www.fabiolopes.tk/blog/python-sort-comparsion/</link>
      <pubDate>Tue, 17 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.fabiolopes.tk/blog/python-sort-comparsion/</guid>
      <description>So I needed to learn how to use decorators in Python.
 I tried to come up with something within my current knowledge and since I was studying sorting algorithms, I decided to use decorators to measure how long each algorithm would take to complete and compare them. I know that it is kind of obvious which one is better in the proposed scenario for anyone with a Bachelor in Computer Science or any experienced developer, but the purpose here was to learn and develop my python skills.</description>
    </item>
    
    <item>
      <title>Obtaining a list of Ceph features from the hexadecimal value</title>
      <link>https://www.fabiolopes.tk/blog/ceph-features-2/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.fabiolopes.tk/blog/ceph-features-2/</guid>
      <description>After some digging i found the list of possible features, its respective kernel version requirement and/or when it became available.
 This can be found in src/include/ceph_features.h, and I got it by cloning the ceph repo at git://github.com/ceph/ceph .
That information might be useful when you are trying to determine if your clients might need a kernel upgrade and what kind of RBD or cephfs features you can enable on your server side without breaking compatibility.</description>
    </item>
    
  </channel>
</rss>
