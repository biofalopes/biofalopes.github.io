[{
    "title": "About",
    "date": "",
    "description": "More about me!",
    "body": "Soon\u0026hellip; ¯\\_(ツ)_/¯\n",
    "ref": "/about/"
  },{
    "title": "Ceph features and its relation to the client kernel version",
    "date": "",
    "description": "How the kernel version used on rbd/cephfs clients reflects on ceph features from the cluster perspective",
    "body": "While working on an upgrade on one of our ceph cluster from Luminous to Nautilus, i needed to come up with a way to detect any client with older versions, and check if we could break anything after the upgrade. I started checking the documentation as always, but all i found was a command called ceph features, which gives a summarized output:\n[root@mon-1 ~]# ceph features { \u0026quot;mon\u0026quot;: { \u0026quot;group\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x3ffddff8eeacfffb\u0026quot;, \u0026quot;release\u0026quot;: \u0026quot;luminous\u0026quot;, \u0026quot;num\u0026quot;: 3 } }, \u0026quot;mds\u0026quot;: { \u0026quot;group\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x3ffddff8eeacfffb\u0026quot;, \u0026quot;release\u0026quot;: \u0026quot;luminous\u0026quot;, \u0026quot;num\u0026quot;: 3 } }, \u0026quot;osd\u0026quot;: { \u0026quot;group\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x3ffddff8eeacfffb\u0026quot;, \u0026quot;release\u0026quot;: \u0026quot;luminous\u0026quot;, \u0026quot;num\u0026quot;: 192 } }, \u0026quot;client\u0026quot;: { \u0026quot;group\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x27018fb86aa42ada\u0026quot;, \u0026quot;release\u0026quot;: \u0026quot;jewel\u0026quot;, \u0026quot;num\u0026quot;: 422 }, \u0026quot;group\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x2f018fb86aa42ada\u0026quot;, \u0026quot;release\u0026quot;: \u0026quot;luminous\u0026quot;, \u0026quot;num\u0026quot;: 95 }, \u0026quot;group\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x3ffddff8eeacfffb\u0026quot;, \u0026quot;release\u0026quot;: \u0026quot;luminous\u0026quot;, \u0026quot;num\u0026quot;: 18 } } } So that got me worried, since i was now looking at 422 clients apparently using jewel and we were already using Nautilus for a while. Since this specific cluster was \u0026ldquo;born\u0026rdquo; in jewel, i thought that it might be the case that many clients didn\u0026rsquo;t get any upgrades since.\nAnother way to see who\u0026rsquo;s connected to the cluster is the command ceph tell mds.\\hostname` client ls`, but it shows only cephfs clients, which solves only a part of the problem. At least we can see the client\u0026rsquo;s IP address (adresses and names omitted with [\u0026hellip;]):\n\u0026quot;inst\u0026quot;: \u0026quot;client.1400410 v1:[...]]:0/1769731892\u0026quot;, \u0026quot;completed_requests\u0026quot;: [], \u0026quot;prealloc_inos\u0026quot;: [], \u0026quot;used_inos\u0026quot;: [], \u0026quot;client_metadata\u0026quot;: { \u0026quot;features\u0026quot;: \u0026quot;0x00000000000001ff\u0026quot;, \u0026quot;entity_id\u0026quot;: [...], \u0026quot;hostname\u0026quot;: [...], \u0026quot;kernel_version\u0026quot;: \u0026quot;4.19.[...]\u0026quot;, \u0026quot;root\u0026quot;: [...] } Continues\u0026hellip;\n",
    "ref": "/blog/ceph-features/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
